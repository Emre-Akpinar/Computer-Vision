{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "\n",
    "vid = cv2.VideoCapture(0)\n",
    "photos = []\n",
    "while True:\n",
    "    ret, frame = vid.read()\n",
    "    try:\n",
    "        cv2.imshow(\"frame\",frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"t\"):\n",
    "          photos.append(frame)  \n",
    "        \n",
    "    except:\n",
    "        print(\"Camera Not Found!\")\n",
    "        break\n",
    "    \n",
    "for i in range(len(photos)):\n",
    "    cv2.imshow(f\"photo{i+1}\",photos[i])\n",
    "cv2.waitKey(0)      \n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-07T15:26:30.951941Z",
     "start_time": "2025-03-07T15:26:00.841120Z"
    }
   },
   "id": "8720dc5f9d81e40c",
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Image"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f235d491bed330a0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Image Reading"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f099b5b071303afd"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "img = cv2.imread(\"IMG&VIDs/me.jpeg\")\n",
    "img_gray = cv2.imread(\"IMG&VIDs/me.jpeg\", cv2.IMREAD_GRAYSCALE) # cv2.IMREAD_GRAYSCALE = 0 (numerical value of)\n",
    "cv2.imshow(\"Profile\", img)\n",
    "cv2.imshow(\"Profile-gray\", img_gray)\n",
    "keyInput = cv2.waitKey(0)\n",
    "print(keyInput) # key inputs ASCII value\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-08T22:35:12.726665Z",
     "start_time": "2025-03-08T22:35:11.819323Z"
    }
   },
   "id": "a77fa0f15cd2fc62",
   "execution_count": 41
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Image Writing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b958a0f271ed13d5"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "(1440, 1440, 3)\n",
      "[148 148 148]\n",
      "[107 138 183]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "img_gray = cv2.imread(\"IMG&VIDs/me.jpeg\", 0)\n",
    "cv2.imwrite(\"IMG&VIDs/me-gray.jpeg\", img_gray)\n",
    "img2 = cv2.imread(\"IMG&VIDs/EmreAkpinar.jpeg\", 0)\n",
    "cv2.imwrite(\"IMG&VIDs/EmreAkpinar-gray.jpeg\", img2)\n",
    "\n",
    "keyInput = cv2.waitKey(0)\n",
    "print(keyInput) # key inputs ASCII value\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "#It seems that openCv write the image with 3 channels wheter or not the image is gray scale(1 channel)\n",
    "#When writing the image tripples the only layer the gray scaled image has as illustrated below\n",
    "\n",
    "\n",
    "img_gray = cv2.imread(\"IMG&VIDs/me-gray.jpeg\")\n",
    "print(img_gray.shape)\n",
    "\n",
    "print(img_gray[500,500])\n",
    "print(img[500,500])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-08T23:19:02.190901Z",
     "start_time": "2025-03-08T23:19:02.136496Z"
    }
   },
   "id": "c63643061f29785b",
   "execution_count": 62
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the colored image it has different values for each color but in the grayscale, it has 3 different layers with same value."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db7092122f2647f0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Video"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "916740052f4b27d7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Capture Camera"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea9c1256fb7fc01"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "vid = cv2.VideoCapture(0) # Laptops cam->0 , changes index if using external device\n",
    "\n",
    "while True:\n",
    "    ret, frame = vid.read()\n",
    "    cv2.imshow(\"frame\", frame)\n",
    "    keyInp = cv2.waitKey(1)\n",
    "    if keyInp == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-07T22:24:27.744377Z",
     "start_time": "2025-03-07T22:24:20.504488Z"
    }
   },
   "id": "c205d54781430cb1",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Opening a video"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da89e573ce2a186f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(\"IMG&VIDs/aTwitchclip.mp4\")\n",
    "\n",
    "if cap.isOpened() == False:\n",
    "    print(\"Error opening video stream or file\")\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret == True:\n",
    "        cv2.imshow(\"clip\", frame)\n",
    "        keyInp = cv2.waitKey(1)\n",
    "        if keyInp == ord('q'):\n",
    "            break\n",
    "            \n",
    "    else:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-07T15:04:54.897814Z",
     "start_time": "2025-03-07T15:04:54.096701Z"
    }
   },
   "id": "228fe06cb000e2ac",
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Capture & Save Camera"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c12800530cfc68"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "vid = cv2.VideoCapture(0)\n",
    "\n",
    "width = int(vid.get(3))\n",
    "height = int(vid.get(4))\n",
    "size = (width, height)\n",
    "\n",
    "result = cv2.VideoWriter(\"IMG&VIDs/record.avi\", cv2.VideoWriter_fourcc(*\"XVID\"), 24, (width, height)) # https://fourcc.org/downloads\n",
    "\n",
    "if vid.isOpened() == False:\n",
    "    print(\"Error opening video stream or file\")\n",
    "    \n",
    "while True:\n",
    "    ret, frame = vid.read()\n",
    "    \n",
    "    if ret == False:\n",
    "        break\n",
    "    \n",
    "    result.write(frame)\n",
    "    cv2.imshow(\"frame\",frame)\n",
    "    keyInp = cv2.waitKey(1)\n",
    "    \n",
    "    if keyInp == ord('q'):\n",
    "        break\n",
    "        \n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-07T15:21:39.257732Z",
     "start_time": "2025-03-07T15:21:19.611355Z"
    }
   },
   "id": "6a173437ad7b5d78",
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Image Properties"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "932d1bd9e814a3e4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import cv2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-08T21:39:01.162111Z",
     "start_time": "2025-03-08T21:39:00.629649Z"
    }
   },
   "id": "35649b01998789c8",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "### item"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f311fdf64b54e5b"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Default-\n",
      "Blue:  70\n",
      "Green:  70\n",
      "Red:  70\n",
      "-Gray-\n",
      "Blue:  70\n",
      "Green:  70\n",
      "Red:  70\n",
      "\n",
      "[70 70 70]\n",
      "[70 70 70]\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(\"IMG&VIDs/me.jpeg\")\n",
    "img_gray = cv2.imread(\"IMG&VIDs/me-gray.jpeg\", cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# img.item(y, x, color)\n",
    "print(\"-Default-\\nBlue: \", img.item(100, 100, 0))\n",
    "print(\"Green: \", img.item(100, 100, 1))\n",
    "print(\"Red: \", img.item(100, 100, 2))\n",
    "\n",
    "print(\"-Gray-\\nBlue: \", img_gray.item(100, 100, 0))\n",
    "print(\"Green: \", img_gray.item(100, 100, 1))\n",
    "print(\"Red: \", img_gray.item(100, 100, 2),end=\"\\n\\n\")\n",
    "\n",
    "print(img[100, 100])\n",
    "print(img_gray[100, 100])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-07T22:37:00.120711Z",
     "start_time": "2025-03-07T22:37:00.079057Z"
    }
   },
   "id": "1436af0c1cf0b612",
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "source": [
    "### itemset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e66802c1777af97"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"IMG&VIDs/me.jpeg\")\n",
    "img_gray = cv2.imread(\"IMG&VIDs/me-gray.jpeg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "#img.itemset((y, x, color), value) #`itemset` was removed from the ndarray class in NumPy 2.0. Use `arr[index] = value` instead.\n",
    "\n",
    "img[100, 100] = 0\n",
    "\n",
    "for y in range(50):\n",
    "    for x in range(50):\n",
    "        img[y, x] = (250,250,250)\n",
    "\n",
    "for y in range(50,100):\n",
    "    for x in range(50,100):\n",
    "        img[y, x, 1] = 0\n",
    "        img[y, x, 0] = 0\n",
    "\n",
    "\n",
    "cv2.imshow(\"Profile\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-08T21:39:27.311383Z",
     "start_time": "2025-03-08T21:39:21.571543Z"
    }
   },
   "id": "cb1a69782f237e5b",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"IMG&VIDs/me.jpeg\")\n",
    "img_gray = cv2.imread(\"IMG&VIDs/me-gray.jpeg\", cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "#img.itemset((y, x, color), value) #`itemset` was removed from the ndarray class in NumPy 2.0. Use `arr[index] = value` instead.\n",
    "\n",
    "img[100, 100] = 0\n",
    "\n",
    "for z in range(0,1340, 100):\n",
    "    for y in range(z,50+z):\n",
    "        for x in range(z,50+z):\n",
    "            img[y, x] = (250,250,250)\n",
    "    \n",
    "    for y in range(50+z,100+z):\n",
    "        for x in range(50+z,100+z):\n",
    "            img[y, x, 1] = 0\n",
    "            img[y, x, 0] = 0\n",
    "\n",
    "\n",
    "cv2.imshow(\"Profile\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-08T21:44:02.995737Z",
     "start_time": "2025-03-08T21:43:57.955750Z"
    }
   },
   "id": "cef1bf1ee94b42e8",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "### shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2ee235785f70185"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1440, 1440, 3)\n",
      "(1440, 1440, 3)\n",
      "height:1440 width:1440 color:3\n",
      "height:1440 width:1440 color:3\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "img = cv2.imread(\"IMG&VIDs/me.jpeg\")\n",
    "img_gray = cv2.imread(\"IMG&VIDs/me-gray.jpeg\", cv2.COLOR_BGR2GRAY)\n",
    "# Since img is a ndarray\n",
    "print(img.shape)\n",
    "print(img_gray.shape)\n",
    "\n",
    "\n",
    "y, x, c = img.shape\n",
    "print(\"height:\", y, \" width:\", x, \" color:\", c, sep=\"\")\n",
    "\n",
    "yg, xg, cg = img_gray.shape\n",
    "print(\"height:\", yg, \" width:\", xg, \" color:\", cg, sep=\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-08T22:24:16.540550Z",
     "start_time": "2025-03-08T22:24:16.510436Z"
    }
   },
   "id": "eb1bddd5bbbe3549",
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "source": [
    "### size"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92f15b45aea574d8"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6220800\n",
      "2073600\n"
     ]
    }
   ],
   "source": [
    "print(img.size)\n",
    "print(img_gray.size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-08T22:03:23.783867Z",
     "start_time": "2025-03-08T22:03:23.780356Z"
    }
   },
   "id": "77186d597fd09404",
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "source": [
    "### datatype"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a2723795d634203c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "print(img.dtype)\n",
    "print(img_gray.dtype)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-08T22:20:53.278181Z",
     "start_time": "2025-03-08T22:20:53.274985Z"
    }
   },
   "id": "86cd75ecaf53de5d",
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "source": [
    "### region of interest"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4cdc6a861a2f0743"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import cv2\n",
    "#roi = img[y1:y2, x1:x2]\n",
    "img2 = cv2.imread(\"IMG&VIDs/EmreAkpinar.jpeg\", cv2.IMREAD_COLOR)\n",
    "\n",
    "#Duplicating interested region\n",
    "roi_m = img2[645:750, 400:650]\n",
    "cv2.imshow(\"Mouth\", roi_m)\n",
    "roi_e = img2[390:460, 340:740]\n",
    "cv2.imshow(\"Eyebrows\", roi_e)\n",
    "roi_n = img2[450:660, 470:600]\n",
    "cv2.imshow(\"Nose\", roi_n)\n",
    "\n",
    "#Adding the region back to the image\n",
    "img2[0:(750-645), 0:(650-400)] = roi_m\n",
    "cv2.imshow(\"Updated image\", img2)\n",
    "\n",
    "\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-08T23:31:04.320887Z",
     "start_time": "2025-03-08T23:30:36.386990Z"
    }
   },
   "id": "63f5889741a2420a",
   "execution_count": 77
  },
  {
   "cell_type": "markdown",
   "source": [
    "### filter color"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c8b29d5451c319a8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "img2 = cv2.imread(\"IMG&VIDs/EmreAkpinar.jpeg\")\n",
    "img2[:, :, 0] = 0  #remove blue\n",
    "#img2[:, :, 1] = 0  #remove green\n",
    "img2[:, :, 2] = 0  #remove red\n",
    "\n",
    "#img2[:, :, 0] = 255  #enhance blue\n",
    "#img2[:, :, 1] = 255  #enhance green\n",
    "#img2[:, :, 2] = 255  #enhance red\n",
    "\n",
    "\n",
    "\n",
    "cv2.imshow(\"filtered\", img2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-08T23:38:30.696767Z",
     "start_time": "2025-03-08T23:38:27.930576Z"
    }
   },
   "id": "d5db2c3c23e795d5",
   "execution_count": 106
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "51950cd8ab87ec9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
